{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c16116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T09:06:27.155772Z",
     "iopub.status.busy": "2025-03-30T09:06:27.155519Z",
     "iopub.status.idle": "2025-03-30T09:06:38.099770Z",
     "shell.execute_reply": "2025-03-30T09:06:38.098829Z"
    },
    "papermill": {
     "duration": 10.950303,
     "end_time": "2025-03-30T09:06:38.101408",
     "exception": false,
     "start_time": "2025-03-30T09:06:27.151105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\r\n",
      "  Downloading ultralytics-8.3.98-py3-none-any.whl.metadata (37 kB)\r\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.5)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\r\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\r\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\r\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.3)\r\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\r\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\r\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2.4.1)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\r\n",
      "Downloading ultralytics-8.3.98-py3-none-any.whl (949 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.0/950.0 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\r\n",
      "Installing collected packages: ultralytics-thop, ultralytics\r\n",
      "Successfully installed ultralytics-8.3.98 ultralytics-thop-2.0.14\r\n",
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "# Install YOLOv8\n",
    "!pip install ultralytics\n",
    "\n",
    "# Import Libraries\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db9f9606",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-30T09:06:38.110383Z",
     "iopub.status.busy": "2025-03-30T09:06:38.110056Z",
     "iopub.status.idle": "2025-03-30T09:06:38.114262Z",
     "shell.execute_reply": "2025-03-30T09:06:38.113664Z"
    },
    "papermill": {
     "duration": 0.00969,
     "end_time": "2025-03-30T09:06:38.115332",
     "exception": false,
     "start_time": "2025-03-30T09:06:38.105642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set Paths (Modify Based on Your Kaggle Directory)\n",
    "DATASET_PATH = \"/kaggle/input/segment\"  # Change to your dataset folder name\n",
    "label_dir = os.path.join(DATASET_PATH, \"valid/labels\")\n",
    "OUTPUT_PATH = \"/kaggle/working/cropped_objects\"  # Folder to save cropped images\n",
    "\n",
    "# Load Data Configuration\n",
    "data_yaml = {\n",
    "    \"train\": os.path.join(DATASET_PATH, \"train/images\"),\n",
    "    \"val\": os.path.join(DATASET_PATH, \"valid/images\"),\n",
    "    \"test\": os.path.join(DATASET_PATH, \"test/images\"),\n",
    "    \"names\": {\n",
    "        0: \"beet\",\n",
    "        1: \"broccoli\",\n",
    "        2: \"cabbage\",\n",
    "        3: \"carrot\",\n",
    "        4: \"cauliflower\",\n",
    "        5: \"cucumber\",\n",
    "        6: \"onion\",\n",
    "        7: \"potato\",\n",
    "        8: \"tomato\",\n",
    "        9: \"yam\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d3a27a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T09:06:38.123230Z",
     "iopub.status.busy": "2025-03-30T09:06:38.123012Z",
     "iopub.status.idle": "2025-03-30T09:06:38.125901Z",
     "shell.execute_reply": "2025-03-30T09:06:38.125288Z"
    },
    "papermill": {
     "duration": 0.008018,
     "end_time": "2025-03-30T09:06:38.127098",
     "exception": false,
     "start_time": "2025-03-30T09:06:38.119080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Paths\n",
    "# DATASET_LABELS_PATH = \"/kaggle/input/segment/valid/labels\"  # Read-only labels\n",
    "# WORKING_LABELS_PATH = \"/kaggle/working/labels\"  # Writable labels directory\n",
    "\n",
    "# # ✅ Ensure the writable directory exists\n",
    "# os.makedirs(WORKING_LABELS_PATH, exist_ok=True)\n",
    "\n",
    "# # ✅ Copy labels from the read-only dataset to the writable directory\n",
    "# for label_file in os.listdir(DATASET_LABELS_PATH):\n",
    "#     src_path = os.path.join(DATASET_LABELS_PATH, label_file)\n",
    "#     dst_path = os.path.join(WORKING_LABELS_PATH, label_file)\n",
    "#     shutil.copy(src_path, dst_path)\n",
    "\n",
    "# print(\"✅ Labels copied to writable directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64cc059e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T09:06:38.134975Z",
     "iopub.status.busy": "2025-03-30T09:06:38.134773Z",
     "iopub.status.idle": "2025-03-30T09:06:38.137531Z",
     "shell.execute_reply": "2025-03-30T09:06:38.136924Z"
    },
    "papermill": {
     "duration": 0.008063,
     "end_time": "2025-03-30T09:06:38.138834",
     "exception": false,
     "start_time": "2025-03-30T09:06:38.130771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INPUT_LABELS_PATH = \"/kaggle/input/segment/train/labels\"  # Read-only directory\n",
    "# WORKING_LABELS_PATH = \"/kaggle/working/labels\"  # Writable directory\n",
    "\n",
    "# # Ensure working directory exists\n",
    "# os.makedirs(WORKING_LABELS_PATH, exist_ok=True)\n",
    "\n",
    "# # Copy label files to writable directory\n",
    "# for label_file in os.listdir(INPUT_LABELS_PATH):\n",
    "#     src_path = os.path.join(INPUT_LABELS_PATH, label_file)\n",
    "#     dst_path = os.path.join(WORKING_LABELS_PATH, label_file)\n",
    "#     shutil.copy(src_path, dst_path)\n",
    "\n",
    "# print(\"✅ Labels copied to working directory.\")\n",
    "\n",
    "# # Now modify the copied files in WORKING_LABELS_PATH\n",
    "# print(\"🛠 Fixing labels...\")\n",
    "# for label_file in os.listdir(WORKING_LABELS_PATH):\n",
    "#     fix_label_file(os.path.join(WORKING_LABELS_PATH, label_file))\n",
    "\n",
    "# print(\"✅ Label fixing completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "765f3a42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T09:06:38.146705Z",
     "iopub.status.busy": "2025-03-30T09:06:38.146464Z",
     "iopub.status.idle": "2025-03-30T09:06:38.149143Z",
     "shell.execute_reply": "2025-03-30T09:06:38.148521Z"
    },
    "papermill": {
     "duration": 0.007891,
     "end_time": "2025-03-30T09:06:38.150297",
     "exception": false,
     "start_time": "2025-03-30T09:06:38.142406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for label_file in os.listdir(WORKING_LABELS_PATH):\n",
    "#     with open(os.path.join(WORKING_LABELS_PATH, label_file), \"r\") as f:\n",
    "#         for line in f.readlines():\n",
    "#             parts = list(map(float, line.strip().split()))\n",
    "#             if len(parts) == 5:\n",
    "#                 _, x, y, w, h = parts\n",
    "#                 if x > 1 or y > 1 or w > 1 or h > 1:\n",
    "#                     print(f\"❌ Invalid bounding box found in {label_file}: {line.strip()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91849f0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T09:06:38.158189Z",
     "iopub.status.busy": "2025-03-30T09:06:38.157981Z",
     "iopub.status.idle": "2025-03-30T09:14:19.845634Z",
     "shell.execute_reply": "2025-03-30T09:14:19.844536Z"
    },
    "papermill": {
     "duration": 461.69344,
     "end_time": "2025-03-30T09:14:19.847329",
     "exception": false,
     "start_time": "2025-03-30T09:06:38.153889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:00<00:00, 79.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.98 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/input/segment/data.yaml, epochs=50, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=cuda, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 17.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    753262  ultralytics.nn.modules.head.Detect           [10, [64, 128, 256]]          \n",
      "Model summary: 129 layers, 3,012,798 parameters, 3,012,782 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:00<00:00, 75.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/segment/train/labels... 702 images, 0 backgrounds, 119 corrupt: 100%|██████████| 702/702 [00:02<00:00, 320.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/beet_027_jpg.rf.0401d68dc968369447381a2555e7c6ae.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0172      1.0964]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/beet_027_jpg.rf.5addae20237a691736f988ee2b5a9fba.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0174      1.0964]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/beet_027_jpg.rf.ba7bb24a3d5259a5d1ba5b387cfaf83d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0205      1.0931]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/beet_311_jpg.rf.204bee8ce9e46fce86036affbf29d7b6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2134       1.223]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/beet_311_jpg.rf.8bedffb36fe3ac62a835de85f57baf57.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.196      1.2065]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/beet_311_jpg.rf.ae1338e7abca62243672e7f4e8b16871.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1896      1.2009]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_024_jpg.rf.09014d9372a35546e4a93ed431a08e84.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1129]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_024_jpg.rf.52ea13f570736ae78beca5813f1d8219.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.063]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_024_jpg.rf.89e51d94620d1d1ae9ef4761c969e17b.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0306]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_026_jpg.rf.572ce9073e0624319cf33222c6692908.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0208]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_026_jpg.rf.b64dda42fc9c64d5bbc081b1a3c1d62d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0224]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_026_jpg.rf.fe398b78a2133b9ddaf48ba603f978b8.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0176]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_031_jpg.rf.0a51508b5333435ce7129968b290d022.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0775]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_031_jpg.rf.8b3e32fb68e2c64afbec6645e7c04b09.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0408]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_031_jpg.rf.d121e5767ad4731b85ade8eb7cffada8.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.049]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_048_jpg.rf.010476557bb3c49b85b1b39dc48ca80b.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0089      1.0147]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_070_jpg.rf.572f89f60a291aef32ec1df3b72f8012.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2158      1.1671]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_070_jpg.rf.69e267955af25707f1a29f38f9ee61cd.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2098      1.1477]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_070_jpg.rf.985d66f016f1c7574963421ca06a8640.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1628      1.2149]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_075_jpg.rf.20e66d48e47126b4c9b045873d4814e0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2018      1.1399]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_075_jpg.rf.24e50d35cfe7f5e5b05951ba31848349.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1228      1.1887]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_075_jpg.rf.6463f2478f599b2133de13de74778469.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1228      1.1887]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_090_jpg.rf.f5bade9fbac01b3d315d459c3ad8fd3b.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0321]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_091_jpg.rf.738956a4039ba4890ba16810fd218221.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0654      1.0673]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_091_jpg.rf.9ba0765e203d9944d4ab1f711b65b1ab.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0673      1.0678]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_091_jpg.rf.ecf07a02623e8c1cf0b180086b6495ac.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0639      1.0665]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_207_jpg.rf.5c918cfb06421058ce034a40e592773a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1813      1.1956]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_207_jpg.rf.e6cd0bfa9644c48c2d557e6173167ce2.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1956      1.1813]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_207_jpg.rf.ef88d23e7e58966df97f282583b4454e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1777      1.1944]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_211_jpg.rf.8222a3f821a96e743b9e4d7ba0fdf4c9.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0983      1.1096]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_211_jpg.rf.9b743f02afd4d75c931d7911a685a558.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.112      1.1018]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_211_jpg.rf.f376c8870db0352944c3c15ba00814a9.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0978      1.1091]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_216_jpg.rf.15ce23156248e363db636c446dbddbe8.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0183      1.0525]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_216_jpg.rf.297f56bdd4da28631ed498e1d2b6d0dd.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0371      1.0022]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/broccoli_216_jpg.rf.f940fff8bc71e5c92e812bfb4bb31c86.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0214]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cabbage_202_jpg.rf.5658133658ddc41b1d52d6aa96ab841b.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0974      1.0637]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cabbage_202_jpg.rf.68ec46ea161e8c5e223573574f775710.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [       1.05      1.0132]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cabbage_202_jpg.rf.ec5bf881f0f5808f6ff89773af80ce3c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1017      1.0645]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cabbage_206_jpg.rf.129a025f22c7be5c70b2d4a1d1dbe170.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1273      1.1156]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cabbage_206_jpg.rf.3d5f0593cd59110ee0b4c797d31fb415.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1268      1.1369]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cabbage_206_jpg.rf.a8e8508ba5937f21dc39925f7ea0b214.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1273      1.1156]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cabbage_207_jpg.rf.55ed88c8091970f1ddc9cb9c87f0895d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1754      1.1753]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cabbage_207_jpg.rf.78643525b5aa628e605c30f02e26c213.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1764      1.1752]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cabbage_207_jpg.rf.b46d1ec5c5d70d3add708d0fd5f2187a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1807      1.1816]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cabbage_213_jpg.rf.0452b4a4adba85b836304f9d49aa2422.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0411      1.0181]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cabbage_213_jpg.rf.29799a450bf7b636ecdb58de7b41d02e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.041      1.0174]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cabbage_213_jpg.rf.4dff3eb4908229cff6fe92d681a53a88.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.032      1.0544]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cabbage_213_jpg.rf.52e9aabaaa91d06bad4e643e55616f02.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.004      1.0275]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cabbage_213_jpg.rf.e6418e148e770ef7527540c6000dd63b.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0134]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cabbage_213_jpg.rf.e8f0ac067794b96de39e962225503dc4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [          1]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cabbage_219_jpg.rf.73949f2e48655e6423207353d647be3f.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0321      1.0095]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cabbage_219_jpg.rf.d2acfa6b898b7b61479d0c6c2a7be05e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0095      1.0321]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cabbage_220_jpg.rf.87ea68432769c98534a9b14b4329c04d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1248      1.1248]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cabbage_220_jpg.rf.c8cb57f81b28e73d4af33cd6acc445d8.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1248      1.1248]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cabbage_220_jpg.rf.eab6cd9e06e2012b82ed06587721583c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1248      1.1248]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/carrot_207_jpg.rf.30c9c01e9279b670120b154db173167a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0827      1.0075]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/carrot_207_jpg.rf.52db979f35bccb07ae7b09f17bc50170.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0909]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/carrot_207_jpg.rf.985e9e97ca1a138d969d284cac806616.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0278      1.0664]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/carrot_211_jpg.rf.61a005c5495db0b64abd74bf8c59c1ad.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0208]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/carrot_211_jpg.rf.aadeb35a2c2c3a6d7e17439058f9886f.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0294]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/carrot_211_jpg.rf.e4baeed6b781dc5a74b4f163e6e635eb.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0208]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cauliflower_046_jpg.rf.307239ff709e211b7b993a43463136ab.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2963      1.2674]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cauliflower_046_jpg.rf.8f56ae52217fe3555b06398eb14d6af6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2454      1.2775]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cauliflower_046_jpg.rf.fe90bf0b153c90c7e74ea1804dd3c63c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2859       1.255]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cucumber_200_jpg.rf.03ccff6f3cb59ac5b7b8341efd24a6bb.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0061]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cucumber_200_jpg.rf.0777319b84306286af5f4b2c3ac90e1d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0076]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cucumber_200_jpg.rf.aaed6b27873ec77414f795ab5df9b255.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0141]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cucumber_206_jpg.rf.1e6e9470b5099b8d77104263a230629a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0287]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cucumber_206_jpg.rf.944d4328bb76f80bddca59d177a6b27a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0334]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cucumber_206_jpg.rf.ebb751ac632cffb3683ef2f33f9ab6ce.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0324]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cucumber_211_jpg.rf.229d73de7c2f6348d33877731403f4fa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0732]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cucumber_211_jpg.rf.6efbb3bbe9c29e8759a683fe3174727a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0722]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cucumber_211_jpg.rf.c3a8ba2613b947f54191ce8352186e9e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0793]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cucumber_214_jpg.rf.19a0f2371c2e35a91e3017235223f6a4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0312]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cucumber_214_jpg.rf.3209ae58f8d6f0f675e76a34a4c331ea.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0312]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/cucumber_214_jpg.rf.64079ad7c04d38e9512401fc01836405.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0148]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/onion_203_jpg.rf.40e1dd27cbbc8183e5b167b59007bec1.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1265      1.0879]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/onion_203_jpg.rf.84b80805a93c0697c823bf86e9c2b4df.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0879      1.1267]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/onion_203_jpg.rf.861058f372c5c9d76a3b70ab2df0202d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1254      1.0834]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/onion_215_webp.rf.3c0ef9211a9329ef7668ab1952c72013.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1352      1.1351]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/onion_215_webp.rf.5e2af4ef067d3cc7f5a69c9aa4076afa.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1348       1.135]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/onion_215_webp.rf.a94556a9948d1d0bd99eec14e1c3832e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1317      1.1322]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/onion_221_jpg.rf.8cb4c9af23779797ae02084cd4945e17.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0043]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/onion_221_jpg.rf.c7a7fe9ab5c370249c78b7aa50673651.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0043]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/onion_221_jpg.rf.e20426cd3b9b1328b21005185d6ab73d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.006]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/potato_201_jpg.rf.43607054fef2a658257a8f28a7de71c8.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0402       1.029]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/potato_201_jpg.rf.a2d2184af1fb1d45633c2dea2a71a1e3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0487       1.011]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/potato_201_jpg.rf.c120fb21070f2f4439272a0aaee86b34.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0453      1.0205]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/potato_203_jpg.rf.54615e8a6b93826e190441b4925cd502.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0318      1.0891]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/potato_203_jpg.rf.aeda83f1fc62b327d294e7b8ecff1b7c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0489]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/potato_203_jpg.rf.cc9b3dbc877a0d449f402c0280b552f9.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0225]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/potato_215_jpg.rf.27e7735a197a3c5b127ffc3d57edea72.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0467      1.2063]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/potato_215_jpg.rf.2f7b0b8b88a9a8ca02363439947f3255.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2005       1.035]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/potato_215_jpg.rf.690e31b8a1c1f9f7fdbadc61e21f731b.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2065      1.0472]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/potato_7_jpg.rf.4f7e708e9e7bf0302d3d7baf2193aeb6.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0874]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/potato_7_jpg.rf.706fe3b2d1adc157a4778a8a5dbc653d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0695]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/potato_7_jpg.rf.eaf3727e53869032d607fb45bb9b034a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0744]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/tomato_200_jpg.rf.66cc2245f5d62385c284ad976a097e0a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1391      1.1238]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/tomato_200_jpg.rf.66d22c5553948d16697743e8a63c96fe.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1691      1.1545]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/tomato_200_jpg.rf.b9e8d4998f281955998729b82aa1d4dd.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1156      1.1327]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/tomato_202_jpg.rf.0db7db3978f81ecef2241f3d127d5113.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1101       1.101]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/tomato_202_jpg.rf.5e753bcd6bb9d228cfa5ebfa29c4b3e7.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0919      1.0821]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/tomato_202_jpg.rf.a7d3cec76894aba3445e12c3210f22b4.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0948      1.1036]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/tomato_207_jpg.rf.278519e6b0c5d35c8cf40504f161ca70.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0507      1.0488]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/tomato_207_jpg.rf.96df0b963e0540bbda53d3b84c29931c.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0563      1.0545]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/tomato_207_jpg.rf.a97ddfb97a251852e0db13165e866e64.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.065      1.0666]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/tomato_210_jpg.rf.b2fd5533e5bf5f92df5293f8343eeb6d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1858       1.185]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/tomato_218_jpg.rf.8b7c7b4b6f67feafa0523a90442165ad.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2674       1.246]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/tomato_218_jpg.rf.df37cb296297c5f14fe527d43365d22d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1631      1.2146]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/tomato_218_jpg.rf.fe06f87c53ec55162a7fd8ae7b7f0f9b.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2574       1.233]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/tomato_219_jpg.rf.728d1204fdb4f18c89829ccb2aa6d15e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0037]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/tomato_219_jpg.rf.9d85d436b37c72567eb880636604d3ea.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      1.009]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/tomato_219_jpg.rf.9e077cdec849748278a671e07a9ee3d3.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0234]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/yam_207_jpg.rf.035889c99da39c7cdec46024c329a8e0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2356]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/yam_207_jpg.rf.151ae70539994b43629d594bbbb376f9.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2385]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/yam_207_jpg.rf.3ed53c710affde864302afcd1f0a5d2a.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2396]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/yam_220_jpg.rf.32fdc3f6c3bcf7fda1ed74ffd0cbe401.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0856]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/yam_220_jpg.rf.64fb0481a4b92445858ed5d799d7b600.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0861]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/input/segment/train/images/yam_220_jpg.rf.e14de5dcc0211e25480dd8199410209e.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0896]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/segment/train is not writeable, cache not saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/segment/valid/labels... 85 images, 1 backgrounds, 9 corrupt: 100%|██████████| 85/85 [00:00<00:00, 211.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/segment/valid/images/beet_008_jpg.rf.c0440924e9b5415eae38b4d9730af631.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0593]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/segment/valid/images/broccoli_056_jpg.rf.576b96978364bb29edab4713895ff55d.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0018]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/segment/valid/images/broccoli_222_jpg.rf.4fc7dae94d667588eb51f88af48e9c66.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0866      1.0877]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/segment/valid/images/cauliflower_205_jpg.rf.04eda5d1f679e9685bb37e1e8454b784.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.2988      1.2744]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/segment/valid/images/cauliflower_218_jpg.rf.cd75051536efeeaa4146975e53bbf7de.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0231      1.0231]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/segment/valid/images/cucumber_204_jpg.rf.60ab18c4c35a3b06a6bf8c49416c2863.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0443]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/segment/valid/images/potato_217_jpg.rf.dda0bdec9ba412bb050c28b7bcc436ff.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.1858      1.1521]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/segment/valid/images/tomato_201_jpg.rf.c9d48dad664bb07dc6e9046db4f08a2b.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0406]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/input/segment/valid/images/yam_205_jpg.rf.4e92bbb9b642f8ac2252727da50534c0.jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     1.0881      1.1234]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/segment/valid is not writeable, cache not saved.\n",
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50      1.16G       1.44      3.716      1.552         28        640: 100%|██████████| 73/73 [00:09<00:00,  7.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371       0.49     0.0776      0.111     0.0641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/50      1.35G      1.447      2.894      1.534         30        640: 100%|██████████| 73/73 [00:07<00:00,  9.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  7.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.205      0.311       0.21      0.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/50      1.35G      1.502      2.615      1.546         46        640: 100%|██████████| 73/73 [00:07<00:00,  9.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.343      0.351      0.276      0.148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/50      1.35G      1.478      2.473      1.587         30        640: 100%|██████████| 73/73 [00:07<00:00,  9.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.466      0.447      0.407      0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/50      1.35G      1.458      2.291      1.554         59        640: 100%|██████████| 73/73 [00:07<00:00,  9.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.348      0.541      0.419      0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/50      1.35G      1.407      2.196      1.524         47        640: 100%|██████████| 73/73 [00:07<00:00,  9.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.501      0.513       0.46      0.258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/50      1.35G      1.444      2.117      1.527        106        640: 100%|██████████| 73/73 [00:07<00:00,  9.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  8.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371       0.43      0.559      0.479      0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/50      1.35G      1.391      2.053      1.476         62        640: 100%|██████████| 73/73 [00:07<00:00,  9.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.507      0.535      0.527      0.278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/50      1.35G      1.375      1.966      1.474         36        640: 100%|██████████| 73/73 [00:07<00:00,  9.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.632      0.561      0.599       0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/50      1.35G      1.357      1.911      1.459         77        640: 100%|██████████| 73/73 [00:07<00:00,  9.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  8.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.525      0.527      0.552      0.321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/50      1.35G      1.363      1.879      1.461         61        640: 100%|██████████| 73/73 [00:07<00:00,  9.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.586      0.495      0.507      0.295\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/50      1.35G      1.322      1.791      1.439         31        640: 100%|██████████| 73/73 [00:07<00:00,  9.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.674      0.567      0.596      0.352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/50      1.35G      1.292      1.739      1.419         27        640: 100%|██████████| 73/73 [00:07<00:00,  9.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.604      0.564      0.577      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/50      1.35G      1.321      1.744      1.427         36        640: 100%|██████████| 73/73 [00:07<00:00,  9.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.594       0.53      0.558      0.336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/50      1.35G      1.293       1.64      1.388         47        640: 100%|██████████| 73/73 [00:07<00:00,  9.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  8.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.586      0.548      0.572      0.336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/50      1.35G      1.272      1.651      1.427         60        640: 100%|██████████| 73/73 [00:07<00:00,  9.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.659      0.613      0.645      0.388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/50      1.35G      1.257      1.531      1.362         68        640: 100%|██████████| 73/73 [00:07<00:00,  9.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.589      0.616      0.607      0.371\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/50      1.35G      1.261      1.545      1.384         48        640: 100%|██████████| 73/73 [00:07<00:00,  9.68it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.652      0.562      0.606      0.358\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/50      1.35G      1.245      1.534      1.367         29        640: 100%|██████████| 73/73 [00:07<00:00,  9.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.695      0.592      0.633      0.392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/50      1.35G      1.232      1.484      1.355         22        640: 100%|██████████| 73/73 [00:07<00:00,  9.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.614      0.593      0.611      0.378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/50      1.35G      1.207      1.423      1.345         38        640: 100%|██████████| 73/73 [00:07<00:00,  9.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.731      0.581      0.665      0.383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/50      1.35G      1.197      1.413      1.345         53        640: 100%|██████████| 73/73 [00:07<00:00,  9.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.656      0.565      0.614      0.379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/50      1.35G      1.175      1.384      1.332         31        640: 100%|██████████| 73/73 [00:08<00:00,  9.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.686      0.594      0.644      0.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/50      1.35G      1.168      1.363       1.34         58        640: 100%|██████████| 73/73 [00:07<00:00,  9.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.695      0.653      0.661      0.399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/50      1.35G      1.173       1.31      1.316         38        640: 100%|██████████| 73/73 [00:07<00:00,  9.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.699      0.564      0.619      0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/50      1.35G      1.159      1.342      1.326         39        640: 100%|██████████| 73/73 [00:07<00:00,  9.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.773       0.57      0.678      0.402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/50      1.35G      1.161      1.324      1.318         36        640: 100%|██████████| 73/73 [00:07<00:00,  9.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.695      0.563      0.625      0.387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/50      1.35G      1.147      1.261      1.309         64        640: 100%|██████████| 73/73 [00:07<00:00,  9.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.721      0.587       0.64      0.391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/50      1.35G      1.142      1.257      1.301         32        640: 100%|██████████| 73/73 [00:07<00:00,  9.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.756      0.566      0.662      0.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/50      1.35G      1.093      1.187      1.282         80        640: 100%|██████████| 73/73 [00:07<00:00,  9.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.749      0.598      0.699      0.436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/50      1.35G       1.11      1.186      1.281         33        640: 100%|██████████| 73/73 [00:07<00:00,  9.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.744      0.591      0.689      0.424\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/50      1.35G      1.102      1.161       1.27         44        640: 100%|██████████| 73/73 [00:07<00:00,  9.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.768      0.613      0.691      0.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/50      1.35G      1.079      1.123      1.254         31        640: 100%|██████████| 73/73 [00:07<00:00,  9.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.822       0.59      0.683      0.413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/50      1.35G      1.076      1.119      1.256         60        640: 100%|██████████| 73/73 [00:07<00:00,  9.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  8.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371        0.7      0.608      0.663      0.409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/50      1.35G      1.064      1.136      1.262         42        640: 100%|██████████| 73/73 [00:07<00:00,  9.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.691      0.672      0.691      0.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/50      1.35G      1.072      1.096      1.248         42        640: 100%|██████████| 73/73 [00:07<00:00,  9.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.729      0.619      0.678      0.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/50      1.35G      1.032      1.086      1.235         35        640: 100%|██████████| 73/73 [00:07<00:00,  9.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.737      0.622      0.697      0.431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/50      1.35G      1.022      1.091      1.226         27        640: 100%|██████████| 73/73 [00:07<00:00,  9.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.734      0.629      0.689      0.433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/50      1.35G      1.032      1.054      1.233         61        640: 100%|██████████| 73/73 [00:07<00:00,  9.71it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.775      0.628        0.7      0.428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/50      1.35G      1.022      1.054      1.228         33        640: 100%|██████████| 73/73 [00:07<00:00,  9.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.765      0.632      0.698      0.425\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/50      1.35G     0.8853      1.002      1.185         38        640: 100%|██████████| 73/73 [00:07<00:00,  9.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.796      0.601      0.685      0.409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/50      1.35G     0.8536      0.925      1.174         33        640: 100%|██████████| 73/73 [00:07<00:00, 10.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.798      0.622      0.687      0.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/50      1.35G     0.8482     0.9207      1.153         14        640: 100%|██████████| 73/73 [00:07<00:00, 10.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371       0.78      0.666      0.705      0.436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/50      1.35G     0.8278     0.9046      1.159         18        640: 100%|██████████| 73/73 [00:06<00:00, 10.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.811      0.654      0.705      0.433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/50      1.35G     0.8301     0.8794       1.13         19        640: 100%|██████████| 73/73 [00:06<00:00, 10.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.762      0.659      0.686      0.424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/50      1.35G     0.8184     0.8729      1.144         29        640: 100%|██████████| 73/73 [00:07<00:00, 10.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.777      0.659      0.693      0.427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/50      1.35G     0.7942     0.8639      1.129         15        640: 100%|██████████| 73/73 [00:07<00:00, 10.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00, 10.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.791      0.635      0.694      0.429\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/50      1.35G     0.7846     0.8331      1.113         33        640: 100%|██████████| 73/73 [00:06<00:00, 10.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.797      0.607      0.687      0.432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/50      1.35G     0.7852     0.8339      1.114         24        640: 100%|██████████| 73/73 [00:07<00:00, 10.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.758      0.643      0.695      0.435\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/50      1.35G      0.789      0.826      1.112         31        640: 100%|██████████| 73/73 [00:07<00:00, 10.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:00<00:00,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.777      0.651      0.703      0.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50 epochs completed in 0.118 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 6.3MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 6.3MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics 8.3.98 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15095MiB)\n",
      "Model summary (fused): 72 layers, 3,007,598 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 5/5 [00:01<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         76        371      0.777      0.651      0.703      0.439\n",
      "                  beet         12         35      0.735        0.8      0.788      0.402\n",
      "              broccoli         21         30      0.584      0.562      0.599      0.389\n",
      "               cabbage         16         22      0.784      0.773      0.833      0.529\n",
      "                carrot         20         70      0.861        0.4      0.517      0.304\n",
      "           cauliflower         10         11      0.785      0.636      0.856      0.485\n",
      "              cucumber         17         54      0.735      0.537      0.596        0.4\n",
      "                 onion         16         27       0.86      0.704      0.729      0.443\n",
      "                potato          5         31      0.878      0.677      0.679      0.501\n",
      "                tomato         17         80      0.732      0.613      0.684      0.393\n",
      "                   yam          4         11      0.816      0.806      0.747      0.544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.4ms preprocess, 3.6ms inference, 0.0ms loss, 9.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
      "✅ Training started successfully!\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# ✅ Load YOLOv8 model\n",
    "model = YOLO(\"yolov8n.pt\")  # Change to 'yolov8s.pt' for better accuracy\n",
    "\n",
    "# ✅ Define the dataset path (Ensure it's a valid YAML file path)\n",
    "data_yaml_path = \"/kaggle/input/segment/data.yaml\"  # Update with correct path\n",
    "\n",
    "# ✅ Check if a GPU is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ✅ Train the model\n",
    "model.train(\n",
    "    data=data_yaml_path,  # Use file path instead of dictionary\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"✅ Training started successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d70a846",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T09:14:20.524090Z",
     "iopub.status.busy": "2025-03-30T09:14:20.523759Z",
     "iopub.status.idle": "2025-03-30T09:14:22.227849Z",
     "shell.execute_reply": "2025-03-30T09:14:22.227131Z"
    },
    "papermill": {
     "duration": 2.063546,
     "end_time": "2025-03-30T09:14:22.229126",
     "exception": false,
     "start_time": "2025-03-30T09:14:20.165580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 broccoli, 7 cucumbers, 1 onion, 10.6ms\n",
      "Speed: 2.2ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 carrot, 7.4ms\n",
      "Speed: 1.7ms preprocess, 7.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 onion, 8 potatos, 7.4ms\n",
      "Speed: 1.8ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 yams, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 broccolis, 4 cucumbers, 5 tomatos, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 cabbage, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 beets, 8.6ms\n",
      "Speed: 2.0ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 cucumbers, 3 tomatos, 10.9ms\n",
      "Speed: 1.7ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 cucumber, 8.4ms\n",
      "Speed: 1.9ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 11 beets, 9.3ms\n",
      "Speed: 1.9ms preprocess, 9.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 broccoli, 4 carrots, 5 tomatos, 7.4ms\n",
      "Speed: 1.7ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 broccoli, 1 cabbage, 11 carrots, 1 cauliflower, 3 onions, 1 tomato, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 broccolis, 3 cabbages, 7.4ms\n",
      "Speed: 1.7ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 cucumber, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 beet, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 broccoli, 1 cabbage, 4 carrots, 1 cauliflower, 2 cucumbers, 3 potatos, 4 tomatos, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 broccolis, 2 cabbages, 4 cucumbers, 1 tomato, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 cabbage, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 broccolis, 1 cabbage, 2 cucumbers, 5 tomatos, 7.4ms\n",
      "Speed: 1.3ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 onion, 2 yams, 7.4ms\n",
      "Speed: 1.7ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 beet, 1 broccoli, 2 onions, 5 tomatos, 7.4ms\n",
      "Speed: 1.7ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 carrot, 3 cucumbers, 13 tomatos, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 onion, 12 potatos, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 cabbages, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 onion, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 broccoli, 7.4ms\n",
      "Speed: 1.7ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 yams, 7.4ms\n",
      "Speed: 1.7ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 broccolis, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 beet, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 cauliflower, 7.4ms\n",
      "Speed: 1.6ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 (no detections), 7.5ms\n",
      "Speed: 1.4ms preprocess, 7.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 onion, 7.4ms\n",
      "Speed: 1.7ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 beets, 7.4ms\n",
      "Speed: 1.7ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 broccoli, 4 cabbages, 2 onions, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 cucumber, 8 tomatos, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 cabbage, 1 cauliflower, 7.4ms\n",
      "Speed: 1.3ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 7 beets, 6.9ms\n",
      "Speed: 1.8ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 onion, 6.9ms\n",
      "Speed: 1.6ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 beets, 7.0ms\n",
      "Speed: 1.7ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 broccolis, 6.9ms\n",
      "Speed: 1.6ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 broccoli, 6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 cauliflower, 6.9ms\n",
      "Speed: 1.3ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 tomatos, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 potatos, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 onion, 6.9ms\n",
      "Speed: 1.6ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 potato, 6.9ms\n",
      "Speed: 1.6ms preprocess, 6.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 beet, 7 broccolis, 1 cabbage, 4 onions, 6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 cabbage, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 broccolis, 1 cabbage, 2 carrots, 1 cauliflower, 2 cucumbers, 2 onions, 1 potato, 3 tomatos, 1 yam, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 potato, 3 tomatos, 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 onions, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 cauliflower, 6.8ms\n",
      "Speed: 1.8ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 beets, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 yams, 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 8 beets, 1 onion, 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 cucumber, 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 yams, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 onion, 6.8ms\n",
      "Speed: 1.5ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 cabbage, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 cabbage, 6.8ms\n",
      "Speed: 1.5ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 9 carrots, 4 tomatos, 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 carrot, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 carrots, 3 tomatos, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 broccolis, 3 tomatos, 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 tomato, 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 carrot, 6.8ms\n",
      "Speed: 1.5ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 carrot, 6.8ms\n",
      "Speed: 1.5ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 broccolis, 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 tomato, 6.8ms\n",
      "Speed: 1.3ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 broccoli, 4 carrots, 4 cucumbers, 1 onion, 4 tomatos, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 broccoli, 6.3ms\n",
      "Speed: 1.6ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 beet, 1 tomato, 6.4ms\n",
      "Speed: 1.3ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 broccoli, 3 carrots, 5 tomatos, 6.3ms\n",
      "Speed: 1.6ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 cucumber, 6.4ms\n",
      "Speed: 1.4ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 broccoli, 1 tomato, 6.4ms\n",
      "Speed: 1.5ms preprocess, 6.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 beets, 6.3ms\n",
      "Speed: 1.6ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 beet, 1 cabbage, 2 cucumbers, 2 onions, 6.3ms\n",
      "Speed: 1.6ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 2 cauliflowers, 6.6ms\n",
      "Speed: 1.5ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 cauliflower, 6.3ms\n",
      "Speed: 1.3ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 3 cucumbers, 2 onions, 1 tomato, 6.3ms\n",
      "Speed: 1.4ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 4 beets, 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 broccoli, 6.3ms\n",
      "Speed: 1.8ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 cabbage, 1 cauliflower, 6.3ms\n",
      "Speed: 1.5ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 cucumber, 6.4ms\n",
      "Speed: 1.6ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 beet, 1 cabbage, 5 cucumbers, 7 tomatos, 6.3ms\n",
      "Speed: 1.5ms preprocess, 6.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "✅ Cropped images saved successfully!\n"
     ]
    }
   ],
   "source": [
    "#Create a directory for saving cropped images\n",
    "for class_name in data_yaml[\"names\"].values():\n",
    "    os.makedirs(os.path.join(OUTPUT_PATH, class_name), exist_ok=True)\n",
    "\n",
    "# Use validation images for detection\n",
    "VALID_IMAGES_PATH = os.path.join(DATASET_PATH, \"valid/images\")\n",
    "\n",
    "for image_name in os.listdir(VALID_IMAGES_PATH):\n",
    "    image_path = os.path.join(VALID_IMAGES_PATH, image_name)\n",
    "\n",
    "    # Load Image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Run YOLOv8 Inference\n",
    "    results = model(image)\n",
    "    \n",
    "    # Loop through each detected object\n",
    "    for obj in results[0].boxes:\n",
    "        x1, y1, x2, y2 = map(int, obj.xyxy[0])  # Get bounding box coordinates\n",
    "        class_id = int(obj.cls[0])  # Get class ID\n",
    "        class_name = data_yaml[\"names\"][class_id]  # Get class label\n",
    "    \n",
    "        # Crop the detected object\n",
    "        cropped_image = image[y1:y2, x1:x2]\n",
    "    \n",
    "        # Save the cropped object\n",
    "        save_path = os.path.join(OUTPUT_PATH, class_name, f\"{image_name}.jpg\")\n",
    "        cv2.imwrite(save_path, cropped_image)\n",
    "\n",
    "print(\"✅ Cropped images saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c83635da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T09:14:22.882313Z",
     "iopub.status.busy": "2025-03-30T09:14:22.881992Z",
     "iopub.status.idle": "2025-03-30T09:14:23.000576Z",
     "shell.execute_reply": "2025-03-30T09:14:22.999672Z"
    },
    "papermill": {
     "duration": 0.443343,
     "end_time": "2025-03-30T09:14:23.001917",
     "exception": false,
     "start_time": "2025-03-30T09:14:22.558574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 4 cabbages, 4 potatos, 13 tomatos, 6.9ms\n",
      "Speed: 2.6ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "✅ Processed unnamed (1).png\n",
      "\n",
      "0: 640x640 1 cabbage, 6 potatos, 7 tomatos, 6.3ms\n",
      "Speed: 2.5ms preprocess, 6.3ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "✅ Processed unnamed.png\n",
      "\n",
      "0: 640x640 4 potatos, 11 tomatos, 6.6ms\n",
      "Speed: 2.5ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "✅ Processed unnamed (2).png\n",
      "🎉 All cropped images saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Paths\n",
    "TEST_IMAGES_PATH = \"/kaggle/input/best-photos\"  # Folder containing test images\n",
    "OUTPUT_PATH = \"/kaggle/working/cropped_objects\"  # Folder to save cropped images\n",
    "# MODEL_PATH = \"/kaggle/working/runs/detect/train/weights/best.pt\"  # Trained YOLOv8 model\n",
    "\n",
    "# Load YOLO Model\n",
    "# model = YOLO(MODEL_PATH)\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "# Process each image in the test_image folder\n",
    "for image_name in os.listdir(TEST_IMAGES_PATH):\n",
    "    image_path = os.path.join(TEST_IMAGES_PATH, image_name)\n",
    "    \n",
    "    # Load Image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"⚠️ Skipping {image_name}: Unable to read image.\")\n",
    "        continue\n",
    "\n",
    "    # Run YOLOv8 Inference\n",
    "    results = model(image)\n",
    "\n",
    "    # Loop through each detected object\n",
    "    for i, obj in enumerate(results[0].boxes):\n",
    "        x1, y1, x2, y2 = map(int, obj.xyxy[0])  # Get bounding box coordinates\n",
    "        class_id = int(obj.cls[0])  # Get class ID\n",
    "        class_name = data_yaml[\"names\"][class_id]  # Get class label\n",
    "\n",
    "        # Create class directory if not exists\n",
    "        class_dir = os.path.join(OUTPUT_PATH, class_name)\n",
    "        os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "        # Crop the detected object\n",
    "        cropped_image = image[y1:y2, x1:x2]\n",
    "\n",
    "        # Save cropped object with unique name\n",
    "        save_path = os.path.join(class_dir, f\"{image_name.split('.')[0]}_{i}.jpg\")\n",
    "        cv2.imwrite(save_path, cropped_image)\n",
    "\n",
    "    print(f\"✅ Processed {image_name}\")\n",
    "\n",
    "print(\"🎉 All cropped images saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75433003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-30T09:01:48.722412Z",
     "iopub.status.busy": "2025-03-30T09:01:48.722081Z",
     "iopub.status.idle": "2025-03-30T09:01:52.051817Z",
     "shell.execute_reply": "2025-03-30T09:01:52.050901Z",
     "shell.execute_reply.started": "2025-03-30T09:01:48.722386Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Define the source folder and output zip path\n",
    "source_folder = \"/kaggle/working/runs\"\n",
    "output_zip = \"/kaggle/working/runs_backup\"\n",
    "\n",
    "# Create a ZIP file (the function automatically adds .zip)\n",
    "shutil.make_archive(output_zip, 'zip', source_folder)\n",
    "\n",
    "print(\"✅ 'runs' folder zipped successfully! Now you can download it.\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6999260,
     "sourceId": 11209191,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6999363,
     "sourceId": 11209332,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6999393,
     "sourceId": 11209371,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6999445,
     "sourceId": 11209437,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6999462,
     "sourceId": 11209478,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 483.216127,
   "end_time": "2025-03-30T09:14:27.825722",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-30T09:06:24.609595",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
