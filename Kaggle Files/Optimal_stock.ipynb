{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from prophet import Prophet\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import google.generativeai as genai\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Garden Vegetable Medley\": 5.983708054173547,\n",
      "    \"Tropical Fruit Salad\": 5.927597701730162,\n",
      "    \"Hearty Potato Curry\": 5.5355362940719886,\n",
      "    \"Fruity Veggie Smoothie\": 5.141572644151567,\n",
      "    \"Spicy Veggie Stir-Fry\": 5.100161965016228\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load the new dataset\n",
    "df = pd.read_csv(\"realistic_dataset.csv\")\n",
    "\n",
    "# Convert date column to datetime format and extract year\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['year'] = df['date'].dt.year\n",
    "\n",
    "# Calculate waste units (stock level - sale units, ensuring no negative values)\n",
    "df['waste_units'] = (df['stock_level'] - df['sale_units']).clip(lower=0)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df[['sale_units', 'price', 'year']]\n",
    "y = df['waste_units']\n",
    "\n",
    "# Split into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Linear Regression model\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict waste units for the test set\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# Create DataFrame to store predictions\n",
    "df_test = df.loc[X_test.index, ['item_name']].copy()\n",
    "df_test['predicted_waste'] = y_pred\n",
    "\n",
    "# Identify high-risk dishes (sorted by highest predicted waste)\n",
    "high_risk = df_test.groupby('item_name')['predicted_waste'].mean().sort_values(ascending=False)\n",
    "\n",
    "# Convert to JSON format\n",
    "high_risk_dish = json.dumps(high_risk.to_dict(), indent=4)\n",
    "\n",
    "# Print high-risk dishes\n",
    "print(high_risk_dish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "High-Risk Ingredients (by average predicted waste in grams):\n",
      "{\n",
      "    \"apple\": 9349.23423464057,\n",
      "    \"potato\": 7465.326938725418,\n",
      "    \"banana\": 6209.388741448644,\n",
      "    \"tomato\": 5267.435093491069,\n",
      "    \"cucumber\": 4639.465994852684,\n",
      "    \"orange\": 4325.481445533489,\n",
      "    \"okra\": 1499.6205016607564\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"realistic_dataset.csv\")\n",
    "\n",
    "# Convert date to datetime format and extract year\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['year'] = df['date'].dt.year\n",
    "\n",
    "# List of ingredients\n",
    "ingredients = [\"apple\", \"banana\", \"cucumber\", \"okra\", \"orange\", \"potato\", \"tomato\"]\n",
    "\n",
    "high_risk_ml = {}\n",
    "\n",
    "# Features for prediction\n",
    "features = ['sale_units', 'price', 'year']\n",
    "\n",
    "for ing in ingredients:\n",
    "    waste_col = f\"waste_{ing}\"\n",
    "    stock_col = f\"stock_{ing}\"\n",
    "    sale_col = \"sale_units\"  # Using total sale units (no individual sale per ingredient)\n",
    "\n",
    "    # Calculate waste for each ingredient\n",
    "    df[waste_col] = (df[stock_col] - df[sale_col]).clip(lower=0)\n",
    "\n",
    "    # Prepare data for model training\n",
    "    X = df[features]\n",
    "    y = df[waste_col]\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train Linear Regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict waste units for the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Store average predicted waste as risk factor\n",
    "    avg_predicted_waste = y_pred.mean()\n",
    "    high_risk_ml[ing] = avg_predicted_waste\n",
    "\n",
    "# Convert to JSON format and print results\n",
    "high_risk = pd.Series(high_risk_ml).sort_values(ascending=False)\n",
    "print(\"\\nHigh-Risk Ingredients (by average predicted waste in grams):\")\n",
    "high_risk_ingredients = json.dumps(high_risk.to_dict(), indent=4)\n",
    "print(high_risk_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:14:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:14:02 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:14:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:14:03 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:14:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:14:04 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:14:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:14:05 - cmdstanpy - INFO - Chain [1] done processing\n",
      "10:14:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "10:14:06 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"optimal_stock_levels\": {\n",
      "    \"apple\": {\n",
      "      \"target\": 35959,\n",
      "      \"buffer\": 9350,\n",
      "      \"total\": 45309\n",
      "    },\n",
      "    \"banana\": {\n",
      "      \"target\": 38001,\n",
      "      \"buffer\": 6210,\n",
      "      \"total\": 44211\n",
      "    },\n",
      "    \"oranges\": {\n",
      "      \"target\": 18773,\n",
      "      \"buffer\": 4326,\n",
      "      \"total\": 23099\n",
      "    },\n",
      "    \"cucumber\": {\n",
      "      \"target\": 21155,\n",
      "      \"buffer\": 4640,\n",
      "      \"total\": 25795\n",
      "    },\n",
      "    \"okra\": {\n",
      "      \"target\": 2656,\n",
      "      \"buffer\": 1500,\n",
      "      \"total\": 4156\n",
      "    },\n",
      "    \"potato\": {\n",
      "      \"target\": 47167,\n",
      "      \"buffer\": 7466,\n",
      "      \"total\": 54633\n",
      "    },\n",
      "    \"tomato\": {\n",
      "      \"target\": 15862,\n",
      "      \"buffer\": 5268,\n",
      "      \"total\": 21130\n",
      "    }\n",
      "  },\n",
      "  \"date\": \"2025-03-30\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holidays\n",
    "from prophet import Prophet\n",
    "\n",
    "# Configure API key\n",
    "genai.configure(api_key=\"gemini_api\")\n",
    "\n",
    "# Load JSON risk data\n",
    "high_risk_items_json = high_risk_dish\n",
    "high_risk_ingredients_json = high_risk_ingredients\n",
    "\n",
    "with open(\"current_predicted_ingredients.json\", \"r\") as file:\n",
    "    predicted_consumption_json = json.load(file)\n",
    "\n",
    "# Load updated dataset (with holiday & weekend spikes)\n",
    "df = pd.read_csv(\"realistic_dataset.csv\")\n",
    "df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "\n",
    "# Get Indian public holidays\n",
    "india_holidays = holidays.country_holidays('IN')\n",
    "\n",
    "# Get user input for target prediction date\n",
    "custom_date = input(\"Enter the date (YYYY-MM-DD): \")\n",
    "target_date = pd.to_datetime(custom_date)\n",
    "\n",
    "# Define recipe ingredient usage (grams per dish)\n",
    "recipes = {\n",
    "    \"Tropical Fruit Salad\": {\"apple\": 130, \"banana\": 90, \"oranges\": 30, \"cucumber\": 20, \"okra\": 0, \"patato\": 80, \"tomato\": 0},\n",
    "    \"Garden Vegetable Medley\": {\"cucumber\": 55, \"okra\": 10, \"tomato\": 50, \"apple\": 50, \"banana\": 30, \"oranges\": 10, \"patato\": 70},\n",
    "    \"Hearty Potato Curry\": {\"patato\": 100, \"tomato\": 50, \"okra\": 5, \"apple\": 60, \"banana\": 80, \"cucumber\": 50, \"oranges\": 40},\n",
    "    \"Fruity Veggie Smoothie\": {\"apple\": 40, \"banana\": 60, \"cucumber\": 45, \"oranges\": 40, \"okra\": 5, \"patato\": 80, \"tomato\": 0},\n",
    "    \"Spicy Veggie Stir-Fry\": {\"patato\": 90, \"tomato\": 50, \"okra\": 5, \"cucumber\": 35, \"apple\": 50, \"banana\": 85, \"oranges\": 50}\n",
    "}\n",
    "\n",
    "# Dictionary to store total predicted ingredient consumption\n",
    "ingredient_totals = {}\n",
    "\n",
    "# Function to check if the target date is a public holiday or weekend\n",
    "def is_special_day(date):\n",
    "    return date in india_holidays or date.weekday() in [5, 6]  # Saturday = 5, Sunday = 6\n",
    "\n",
    "# Adjust sales forecast based on special demand periods\n",
    "for item in df['item_name'].unique():\n",
    "    df_item = df[df['item_name'] == item][['date', 'sale_units']].copy()\n",
    "    df_item = df_item.rename(columns={'date': 'ds', 'sale_units': 'y'})\n",
    "    \n",
    "    # Train Prophet model on historical sales\n",
    "    model = Prophet()\n",
    "    model.fit(df_item)\n",
    "    \n",
    "    # Predict sales for the target date\n",
    "    future_df = pd.DataFrame({'ds': [target_date]})\n",
    "    forecast = model.predict(future_df)\n",
    "    \n",
    "    predicted_sales = forecast['yhat'].iloc[0]\n",
    "\n",
    "    # If holiday or weekend, increase stock by 20-30%\n",
    "    if is_special_day(target_date):\n",
    "        predicted_sales *= np.random.uniform(1.2, 1.3)\n",
    "\n",
    "    # Apply seasonality-based stock adjustment\n",
    "    seasonal_multiplier = {\n",
    "        1: 0.9,  2: 0.92, 3: 1.05, 4: 1.1, 5: 1.15, 6: 1.2,\n",
    "        7: 1.25, 8: 1.3, 9: 1.2, 10: 1.5, 11: 1.4, 12: 1.35\n",
    "    }\n",
    "    predicted_sales *= seasonal_multiplier.get(target_date.month, 1.0)\n",
    "\n",
    "    # Calculate ingredient consumption based on recipe\n",
    "    if item in recipes:\n",
    "        for ingredient, grams_per_dish in recipes[item].items():\n",
    "            consumption = predicted_sales * grams_per_dish\n",
    "            ingredient_totals[ingredient] = ingredient_totals.get(ingredient, 0) + consumption\n",
    "\n",
    "# Apply buffer stock (5-15%) for volatile ingredients\n",
    "for ingredient in ingredient_totals.keys():\n",
    "    buffer_multiplier = np.random.uniform(1.05, 1.15)\n",
    "    ingredient_totals[ingredient] = int(np.round(ingredient_totals[ingredient] * buffer_multiplier))\n",
    "\n",
    "# Create JSON object\n",
    "predicted_ingredient_consumption_json = json.dumps({\n",
    "    \"target_date\": custom_date,\n",
    "    \"predicted_ingredient_consumption\": ingredient_totals\n",
    "}, indent=4)\n",
    "\n",
    "# Format prompt for Gemini\n",
    "prompt = f\"\"\"\n",
    "Based on the following updated data:\n",
    "- High-risk items with lower predicted sales: {json.dumps(high_risk_items_json, indent=4)}\n",
    "- High-risk ingredients prone to wastage: {json.dumps(high_risk_ingredients_json, indent=4)}\n",
    "- Updated predicted ingredient consumption (accounting for holidays, weekends, and seasonality): {json.dumps(predicted_ingredient_consumption_json, indent=4)}\n",
    "\n",
    "Generate a JSON object containing the optimal stock levels for each ingredient. The stock levels should:\n",
    "- Ensure sufficient availability while preventing over-purchasing.\n",
    "- Adapt dynamically to holiday spikes and seasonal changes.\n",
    "- Minimize wastage using a buffer stock mechanism.\n",
    "\n",
    "Strictly return only the JSON object with optimal stock levels, without any additional text or explanations.\n",
    "\"\"\"\n",
    "\n",
    "# Generate response from Gemini\n",
    "response = genai.GenerativeModel(\"gemini-2.0-flash\").generate_content(prompt)\n",
    "\n",
    "# Print Gemini's response\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
